---
layout: post
title: "深度学习入门：基于Python的理论与实现（3）"
author: "yurj"
subtitle: "深度学习"
catelog: true
header-style: text
tags:
  - AI
  - 深度学习
  - Python
  - 学习笔记
---

# 第八章 深度学习

深度学习是加深了层的深度神经网络

基于之前介绍的网络，只需通过叠加层，就可以创建深度网络

## 加深网络

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.17.20.png" alt="截屏2020-05-12 下午2.17.20" style="zoom:50%;" />

基于3 * 3的小型滤波器的卷积层

激活函数是ReLU

全连接层的后面使用Dropout层

基于Adam的最优化

使用He初始值作为权重初始值

这次的深度CNN尽管识别精度很高，但是对于某些图像，也犯了和人类同样的识别错误。从这一点上，我们也可以感受到深度CNN中蕴藏着巨大的可能性

### 进一步提高识别精度

对于MNIST数据集，层不同特别深就获得了目前最高的识别精度。一般认为，这是因为对于手写数字识别这样一个比较简单的任务，没有必要将网络的表现力提高到那么高的程度。因此，可以说加深层的好处并不大。而之后要介绍的大规模的一般物体识别的情况，因为问题复杂，所以加深层对提高识别精度大有裨益

集成学习 学习率衰减 Data Augmentation 数据扩充

Data Augmentation基于算法人为的扩充输入图像

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.23.52.png" alt="截屏2020-05-12 下午2.23.52" style="zoom:50%;" />

虽然这个看上去只是一个简单的技巧，不过经常会有很好的效果

### 加深层的动机

加深层的网络可以减少网络的参数数量。说的详细一点，就是与没有加深层的网络相比，加深了层的网络可以用更少的参数达到同等水平（或者更强的）表现力

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.38.05.png" alt="截屏2020-05-12 下午2.38.05" style="zoom:50%;" />

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.38.41.png" alt="截屏2020-05-12 下午2.38.41" style="zoom:50%;" />

通过叠加卷积层，参数数量减小了。而且，这个参数数量之差会随着层的加深而变大

叠加小型滤波器来加深网络的好处可以减少参数的数量，扩大感受野（receptive field，给神经元施加变化的某个局部空间区域）。并且。通过叠加层，将ReLU等激活函数夹在卷积层的中间，进一步提高了网络的表现力。这是因为向网络添加了基于激活函数的非线性表现力，通过非线性函数的叠加，可以表现更加复杂的东西

加深层的另一个好处是使学习更加高效

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.43.07.png" alt="截屏2020-05-12 下午2.43.07" style="zoom:50%;" />

## 深度学习的小历史

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.44.32.png" alt="截屏2020-05-12 下午2.44.32" style="zoom:50%;" />

### ImageNet

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.45.53.png" alt="截屏2020-05-12 下午2.45.53" style="zoom:50%;" />

### VGG

VGG是由卷积层和池化层构成的基础的CNN。不过，它的特点是在于将有权重的层（卷积层或者全连接层）叠加至16层（或者19层），具备了深度（根据层的深度，有时也称VGG16或VGG19）

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.48.31.png" alt="截屏2020-05-12 下午2.48.31" style="zoom:50%;" />

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.48.48.png" alt="截屏2020-05-12 下午2.48.48" style="zoom:50%;" />

### GoogLeNet

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.49.46.png" alt="截屏2020-05-12 下午2.49.46" style="zoom:50%;" />

它基本上和之前介绍的CNN结构相同，不过GoogleNet的特征是，网络不仅在纵向上有深度，在横向上也有深度（广度）

GoogLeNet在横向上有宽度，这称为Inception结构

### ResNet

微软团队开发的网络。它的特征在于具有比以前的网络更深的结构

P246

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.53.34.png" alt="截屏2020-05-12 下午2.53.34" style="zoom:50%;" />

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.53.45.png" alt="截屏2020-05-12 下午2.53.45" style="zoom:50%;" />

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.53.58.png" alt="截屏2020-05-12 下午2.53.58" style="zoom:50%;" />

## 深度学习的高速化

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午2.55.11.png" alt="截屏2020-05-12 下午2.55.11" style="zoom:50%;" />

大部分时间都被耗费在卷积层上

如何高速、高效地进行卷积层中的运算是深度学习的一大课题

卷积层中进行的运算可以追溯至乘积累加运算

### 基于GPU的高速化

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午3.18.28.png" alt="截屏2020-05-12 下午3.18.28" style="zoom:50%;" />

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午3.18.41.png" alt="截屏2020-05-12 下午3.18.41" style="zoom:50%;" />

### 分布式学习

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午3.19.51.png" alt="截屏2020-05-12 下午3.19.51" style="zoom:50%;" />

Google的TensorFolw、微软的CNTK在开发过程中高度重视分布式学习。以大数据中心的低延迟、高吞吐网络作为支撑，基于这些框架的分布式学习呈现出惊人的效果

### 运算精度的位数缩减

神经网络并不那么需要数值精度的位数。这是神经网络的一个重要性质

这个性质是基于神经网络的健壮性而产生的。这里所说的健壮性是指，比如，即便输入图像附有一些小的噪声，输出结果也仍然保持不变。可以认为，正是因为有了这个健壮性，流经网络的数据即便有所劣化，对输出结果的影响也较小

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午3.25.05.png" alt="截屏2020-05-12 下午3.25.05" style="zoom:50%;" />

<img src="/Users/yurunjie/Library/Application Support/typora-user-images/截屏2020-05-12 下午3.25.16.png" alt="截屏2020-05-12 下午3.25.16" style="zoom:50%;" />

## 深度学习的应用案例

### 物体检测

P253

### 图像分割

P255

### 图像标题的生成

P256

## 深度学习的未来

### 图像风格转换

P258

### 图像的生成

P259

### 自动驾驶

P261

### Deep Q-Networl（强化学习）

P262
